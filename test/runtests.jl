using SmoothPeriodicStatsModels
using Test
using Distributions, Random
using Optimization, OptimizationOptimJL
using Ipopt, OptimizationMOI

# EM for Mixture 
@testset "fit_mle_trig_exp2_EM" begin

    #TODO: for now it just test that this runs, the results are not tested (but so far it reaches a local minima so...)
    Random.seed!(1234)
    # K = 2
    # ð”»ð•–ð•˜ = 1
    f(Î¸) = MixtureModel([Exponential(Î¸[1]), Exponential(Î¸[2])], [Î¸[3], 1-Î¸[3]])
    f(t, Î¸) = f([Ïƒâ‚œ(t, Î¸[:,1]), Ïƒâ‚œ(t, Î¸[:,2]), Î±â‚œ(t, Î¸[:,3])])

    Î¸Ïƒ1 = [1, 1, -0.2]
    Î¸Ïƒ2 = [3, -0.5, 0.6]
    Î¸Î± = [0.1, -0.5, 1]
    Î¸true = hcat(Î¸Ïƒ1, Î¸Ïƒ2, Î¸Î±)
    
    # Data
    T = 100
    N = 20000
    n2t = repeat(1:T, NÃ·T)
    y = [rand(f(t/T, Î¸true)) for t in n2t]
    
    #* guess
    Î¸Ïƒ10 = [0, 0, 0]
    Î¸Ïƒ20 = [5, 0, 0.]
    Î¸Î±0 = [0.0, 0.2, 0]
    Î¸0 = hcat(Î¸Ïƒ10, Î¸Ïƒ20, Î¸Î±0)
    mix0 = [f(t/T, Î¸0) for t in 1:T]
    Î¸Ïƒ0 = [Î¸Ïƒ10, Î¸Ïƒ20]
    
    mixt, Î¸_Î±, Î¸_Y, history = fit_mle(mix0, permutedims(Î¸Î±0), Î¸Ïƒ0, y, n2t;
        display=:none, maxiter=1000, tol=1e-5, robust=false, silence=true, warm_start=true)
    
    @test all(diff(history["logtots"]) .> 0) # increasing loglikelihood
    # @btime fit_mle($mix0, $permutedims(Î¸Î±0), $Î¸Ïƒ0, $y, $n2t;display=:none, maxiter=1000, tol=1e-5, robust=false, silence=true, warm_start=true)
    # 765.973 ms (1833703 allocations: 330.39 MiB)
    # local minima though
    # ([Î¸_Y2[1] Î¸_Y2[2] Î¸_Î±2'])
    # 3Ã—3 Matrix{Float64}:
    #   1.01778    3.03886   0.106579
    #   1.05301   -0.509514  0.234709
    #  -0.280736   0.649009  0.901227
    # 
    # rangeT = (1:T)/T
    # plot(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸Ïƒ1))
    # plot!(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸Ïƒ2))
    # plot!(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸_Y[1]), c= 1,s=:dot)
    # plot!(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸_Y[2]), c= 2,s=:dot)
    # plot!(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸_Y2[1]), c= 1,s=:dot)
    # plot!(rangeT,tÌƒ-> Ïƒâ‚œ(tÌƒ, Î¸_Y2[2]), c= 2,s=:dot)
    # plot(rangeT,tÌƒ-> Î±â‚œ(tÌƒ, Î¸Î±))
    # plot!(rangeT,tÌƒ-> Î±â‚œ(tÌƒ, permutedims(Î¸_Î±)))
end

# Optim for Mixture 
@testset "fit_mle_trig_exp2_Optim" begin
    Random.seed!(1234)

    f(Î¸) = MixtureModel([Exponential(Î¸[1]), Exponential(Î¸[2])], [Î¸[3], 1 - Î¸[3]])
    f(t, Î¸) = f([Ïƒâ‚œ(t, Î¸[1:3]), Ïƒâ‚œ(t, Î¸[4:6]), Î±â‚œ(t, Î¸[7:9])])
    
    Î¸Ïƒ1 = [1, 1, -0.2]
    Î¸Ïƒ2 = [3, -0.5, 0.6]
    Î¸Î± = [0.1, -0.5, 1]
    Î¸true = hcat(Î¸Ïƒ1, Î¸Ïƒ2, Î¸Î±)
    
    # Data
    T = 100
    N = 20000
    n2t = repeat(1:T, NÃ·T)
    y = [rand(f(t/T, vec(Î¸true))) for t in n2t]
    
    â„“(Î¸, x) = -sum(logpdf(f(t / T, Î¸), x[n]) for (n, t) in enumerate(n2t)) # = -loglikelihood

    #* guess
    Î¸Ïƒ10 = [0, 0, 0]
    Î¸Ïƒ20 = [5, 0, 0.]
    Î¸Î±0 = [0.0, 0.2, 0]
    Î¸0 = hcat(Î¸Ïƒ10, Î¸Ïƒ20, Î¸Î±0)

    sol_Ipopt = fit_mle(OptimMLE(â„“, Ipopt.Optimizer(), vec(Î¸0)), y)
    sol_NewtonTR = fit_mle(OptimMLE(â„“, NewtonTrustRegion(), vec(Î¸0)), y)

    @test sol_Ipopt.u â‰ˆ vec(Î¸true) rtol = 5e-2
    @test sol_NewtonTR.u â‰ˆ vec(Î¸true) rtol = 5e-2
end

# HMM
@testset "Sample from HMM" begin
    K = 4
    T = 20
    D = 10
    N = 100
    Î¾ = [1; zeros(K-1)]
    ref_station = 1

    # Test that the HMM is well definied with different order of chain (= "local memory" in my jargon)
    for order in 0:3
        hmm_random = randhierarchicalPeriodicHMM(K, T, D, order; Î¾=Î¾, ref_station=ref_station)

        z, y = rand(hmm_random, N, seq = true, z_ini = 1, y_ini = zeros(Int, order, D))

        y = rand(hmm_random, N)
    end

    #TODO add test comparing order = 0 to PeriodicHMM (it should be exactly the same)
end
